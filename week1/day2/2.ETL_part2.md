# Extract:

## Extracting Data from Files

Objective: Understand how to extract data from different file formats using Python.

Practical Task: Extract data from a file using the pandas library. 

- local files

```
import pandas as pd

df = pd.read_csv("country_data.csv")

```

- files in different location

```
import pandas as pd

df = pd.read_csv("data/country_data.csv")

```

- file from URL

```
import pandas as pd

df = pd.read_csv("https://raw.githubusercontent.com/ChpcTraining/css2024_data/main/country_data.csv")

```

  
- Different types of files: Excel, JSON, text, CSV


```
import pandas as pd


# df = pd.read_csv("data/country_data.csv")
# index issue - , index_col=0

# df = pd.read_csv("data/GenoType Dataset.csv")
# ???

# df = pd.read_csv("data/Geospatial Data.txt",sep=";")
# delim issue, semi colon
# name issue

# df = pd.read_csv("data/pulse_data.csv")
# nan issue

# df = pd.read_excel("data/residentdoctors.xlsx")
# column name not consistent, spaces
# Age-dist has years in it
# nan

#df = pd.read_json("data/student_data.json")
# how to read in subfields

df = pd.read_csv("data/student-mat.csv")
# pretty clean

# df = pd.read_csv("data/time_series_data.csv")
# first column unamed_0
# df = pd.read_csv('data/time_series_data.csv', index_col=0)


# Display the DataFrame
print(df)
```

## Other options:

- Webscraping
  
- Connecting to Databases


# Transform:


## Lesson 4: Data Cleaning and Preprocessing

Objective: Focus on cleaning and preprocessing extracted data for analysis.

Practical Task: Use pandas for tasks like handling missing values, removing duplicates, and transforming data types. Discuss the importance of data quality.


## Lesson 5: Applying Data Transformations

Objective: Introduce transformations such as aggregations, merging, and filtering.

Practical Task: Demonstrate how to aggregate data using groupby in pandas. Merge datasets using different join types. Filter and manipulate data to create new variables.

- merge files


## Lesson 6: Implementing Advanced Transformations

Objective: Teach advanced transformations like pivot tables and custom functions.

Practical Task: Create a pivot table using pandas. Write custom functions to transform data based on specific requirements.

# Load:

## Lesson 7: Writing to Files and Databases

Objective: Understand how to load transformed data back into different storage systems.

Practical Task: Write transformed data to a CSV file, Excel file, and a PostgreSQL database. Discuss the benefits and considerations for each storage method.


## Lesson 8: Automating ETL Pipelines

Objective: Learn how to automate ETL processes for efficiency.

Practical Task: Use tools like Apache Airflow or create simple Python scripts to automate ETL pipelines. Schedule tasks to run at specified intervals.

## Lesson 9: Monitoring and Error Handling

Objective: Emphasize the importance of monitoring and handling errors in ETL processes.

Practical Task: Implement error handling mechanisms in a Python script. Use logging to track the progress of an ETL pipeline and handle exceptions.
Overall Project:

## Lesson 10: Final Project

Objective: Apply all the ETL concepts learned in a comprehensive project.

Practical Task: Design and implement an end-to-end ETL pipeline for a real-world dataset. Include extraction from different sources, thorough data transformations, and loading into a database or file. Present and discuss the project in class.
Remember to encourage collaboration, provide opportunities for questions and problem-solving, and emphasize best practices throughout the lessons.
